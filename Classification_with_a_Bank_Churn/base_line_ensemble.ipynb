{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8455e9c6-259f-4d4f-b343-3d4f5d18d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import pandas as pd; pd.set_option('display.max_columns', 100)\n",
    "from pandas.core.common import flatten\n",
    "import numpy as np\n",
    "import shap\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "from functools import partial\n",
    "from scipy.stats import mode\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "# import plotly.express as px\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler,PowerTransformer, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, cohen_kappa_score, log_loss, f1_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# import optuna\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "from View import MyClass\n",
    "mc = MyClass()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d00d384-a2ef-4689-bc40-d8bc83872654",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb = {\n",
    "        \"n_estimators\": 1993,\n",
    "        \"learning_rate\": 0.009906548674016816,\n",
    "        \"subsample\": 0.5000411100811685,\n",
    "#         'colsample_bylevel': 0.5853177112754828,\n",
    "        \"loss_function\": \"Logloss\",\n",
    "        \"eval_metric\": \"AUC\",\n",
    "        \"task_type\": \"CPU\",\n",
    "        #\"max_bin\": 20,\n",
    "        \"verbose\": False,\n",
    "        \"max_depth\": 5,\n",
    "        \"l2_leaf_reg\": 20,\n",
    "        \"early_stopping_rounds\": 100,\n",
    "#         \"thread_count\": 6,\n",
    "        # \"random_seed\": 42,\n",
    "        \"class_weights\" : (1, 2),\n",
    "        \"random_state\": 42\n",
    "        }\n",
    "params_lgbm = {\"objective\":'binary',\n",
    "          \"n_estimators\" : 3000,\n",
    "                             \"max_depth\" : 6,\n",
    "                             \"learning_rate\" : 0.01,\n",
    "                             \"num_leaves\" : 20,\n",
    "                             \"reg_alpha\" : 4,\n",
    "                             \"reg_lambda\" : 4,\n",
    "                             \"subsample\" : 0.7,\n",
    "                             \"colsample_bytree\" : 0.7,\n",
    "                             \"verbose\" : -100,\n",
    "                              \"min_data_in_bin\": 1,\n",
    "                              \"min_data_in_leaf\" : 1\n",
    "}\n",
    "params_xgb = {\n",
    "            # \"objective\":'binary',\n",
    "            'max_delta_step': 3,\n",
    "            'min_child_weight': 2,\n",
    "            \"n_estimators\" : 2466,\n",
    "            'alpha': 2,\n",
    "             'colsample_bytree': 0.7,\n",
    "             'eta': 0.003419782719339618,\n",
    "             'gamma': 1,\n",
    "             'lambda': 1,\n",
    "             'max_depth': 8,\n",
    "             'subsample': 0.31098721316506717\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98cbebee-199c-4476-9f4c-66f30d93db18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Визуализация и предобработка данных\n",
      "_________________________________________________\n",
      "* Метод \"view_csv\" принимает DataFrame и выводит данные о нем\n",
      "возвращает categorical, numerical\n",
      "\n",
      "* Метод \"stat_frame\" принимает DataFrame и возвращает DataFrame со статистиками\n",
      "\n",
      "* Метод corr(data, target):\n",
      "data: DataFrame\n",
      "target : str\n",
      "\n",
      "* Графики\n",
      "* Метод connect_sign(train, test, columns) Определяет похожи ли признаки в train и test\n",
      "train, test: DataFrame\n",
      "columns: list( список колонок без целевой переменной)\n",
      "\n",
      "* Метод distribution_sign(train, numerical, target_name='target', log=False): распределение признаков\n",
      "train: DataFrame\n",
      "numerical: признаки числовые\n",
      "target_name: str имя целевой переменной\n",
      "log: bool если нужно логарифмировать признаки\n",
      "\n",
      "* Метод similarity_sign(data, data_test, numericaal): похожесть признаков и вычисление p-value\n",
      "data, data_test: DataFrame\n",
      "numericaal: list числовые признаки\n",
      "\n",
      "Работа с данными\n",
      "__________________________________________________\n",
      "\n",
      "* Метод transformer(train, test, cont_cols, target) создает новые столбцы используя математические преобразования\n",
      "log, sqrt, box_cox, Yeo-Johnson\n",
      "train, test: DataFrame\n",
      "cont_cols: list( колонки для преобразования)\n",
      "target: str\n",
      "return train_copy, test_copy\n",
      "\n",
      "* Метод encoder(data, data_t, aggs): кодирует категориальные признаки OneHot, Label, frequency\n",
      "data, data_t: DataFrame\n",
      "aggs: list ( список признаков для кодирования)\n",
      "return: data, data_test\n",
      "\n",
      "* Метод \"median_mode\" меняет в числовых данных пропуски на медиану, в категориальных на моду\n",
      "\n",
      "* Метод \"percentile_99_1\" принимает data: DataFrame, data_stat : DataFrame( возвращает метод \"stat_frame\")\n",
      "возвращат данные где больше 99 перцетиля и меньше 1(используется метод for, не рекомендуется где очень много столбцов)\n",
      "\n",
      "* метод \"shap\" (model, X_train, shap_limit=0) выводит наиболеее важные признаки\n",
      "model: model, X_train: данные на которых обучалась модель, shap_limit: порог для наихудших признаков\n",
      "возвращает признаки с важностью с порогом равным или меньше (shap_limit)\n",
      "и словарь признаков отсортированный по важности\n",
      "return bad_feature, dict_feature\n",
      "\n",
      "* метод split_group (data, features: List)\n",
      "Разбивает некоторые признаки на 5 групп\n",
      "возвращает data: DataFrame\n",
      "\n",
      "Разбиение данных\n",
      "____________________________________________________\n",
      "\n",
      "* Метод \"train_split_dis\" - Разбиение данных с несбалансированной бинарной целевой переменной\n",
      "на train, test, valid по умолчанию test_size = 0.2, valid_size=0.2\n",
      "принимает data: DataFrame, y: str(имя целевой переменной), valid_size: float, test_size: float\n",
      "min_sign: int(значение target которых мало)\n",
      "возвращает x_train, x_valid, y_train, y_valid, x_test, y_test\n",
      "\n",
      "* Метод \"train_split\" - Разбиение данных на train, test, valid по умолчанию test_size = 0.2, valid_size=0.2\n",
      "принимает data: DataFrame, y: str(имя целевой переменной), valid_size: float, test_size: float\n",
      "возвращает x_train, x_valid, y_train, y_valid, x_test, y_test\n",
      "\n",
      "Обучение Моделей\n",
      "__________________________________________________\n",
      "\n",
      "* Метод hill_climbing(x, y, x_test=None) находит лучший коэффициент для обьеденения предсказаний нескольких моделей\n",
      "пример: (oof_1 * n1 + oof_2 * n2 + oof_3 * n3) (n1+n2+n3) = 1\n",
      "x, x_test : DataFrame({model: oof,\n",
      "                       model_2: oof_2})\n",
      "y: список целевых ответов для модели X_train['target']\n",
      "x_test если нужны предсказания для тестовых данных\n",
      "\n",
      "* Метод fit_kfold (data, target, model, name_model, params=False, trh_flag=False, threshold=0.4, fold=10, best_sign=5,\n",
      "                  oof=False, eval_set=False)\n",
      "trh_flag: параметр bool, если True модель предсказывает вероятность нужно указать порог: threshold\n",
      "выше какого значения будет еденица\n",
      "best_sign: возвращает лучшие для модели признаки по умолч: 5\n",
      "eval_set: bool если True данные делятся на train, test, valid и при обучении будет следить за переобучением\n",
      "\n",
      "return Model_md, dict_fold\n",
      "\n",
      "Model_md: модель\n",
      "dict_fold: словарь с id строк на разных фолдах( можно взять тот фолд где лучший прогноз)\n",
      "\n",
      "* Метод \"catboost_base\" -BaseLine принимает x:DataFrame, x_val:DataFrame, y: Series, y_val: Series,params:dict\n",
      "параметры catboost: None, можно передать\n",
      "возвращает модель\n",
      "\n",
      "* Метод \"xgb_base\" -BaseLine принимает x:DataFrame, x_val:DataFrame, y: Series, y_val: Series,params:dict\n",
      "параметры xgboost: None, можно передать\n",
      "возвращает модель\n",
      "\n",
      "* Метод \"forest_base\" -BaseLine принимает x:DataFrame, x_val:DataFrame, y: Series, y_val: Series,\n",
      "возвращает модель\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(mc.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c93b9b-e8fb-414e-8120-3af1e8fe622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv', 'test.csv', 'train.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393106c1-63e1-4b48-826d-02d372b4d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sub = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e45597-b18c-4cd4-9279-47ae0b4d1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 165034, cols: 14\n",
      "\n",
      "Категориальные признаки: \n",
      "Всего категориальных признаков: 3\n",
      "surname уникальных значений: 2797\n",
      "geography уникальных значений: 3, ['France' 'Spain' 'Germany']\n",
      "gender уникальных значений: 2, ['Male' 'Female']\n",
      "\n",
      "Числовые признаки: \n",
      "\n",
      "Всего числовых признаков: 11\n",
      "['hascrcard', 'estimatedsalary', 'numofproducts', 'exited', 'id', 'customerid', 'tenure', 'isactivemember', 'creditscore', 'balance', 'age']\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      "В данных пропусков нету\n",
      "rows: 110023, cols: 13\n",
      "\n",
      "Категориальные признаки: \n",
      "Всего категориальных признаков: 3\n",
      "surname уникальных значений: 2708\n",
      "geography уникальных значений: 3, ['France' 'Germany' 'Spain']\n",
      "gender уникальных значений: 2, ['Female' 'Male']\n",
      "\n",
      "Числовые признаки: \n",
      "\n",
      "Всего числовых признаков: 10\n",
      "['hascrcard', 'estimatedsalary', 'numofproducts', 'id', 'customerid', 'tenure', 'isactivemember', 'creditscore', 'balance', 'age']\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      " для проверки isna: 0\n",
      "В данных пропусков нету\n"
     ]
    }
   ],
   "source": [
    "cat, num = mc.view_csv(train)\n",
    "cat_t, num_t = mc.view_csv(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ce9325c-bb4c-4365-a3b4-5e2919f58f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"surname\", axis=1)\n",
    "test = test.drop(\"surname\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a5fb56-e2f7-4a9e-a68c-1343d24504dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = ['geography', 'gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1280bb-7a38-40c4-bf97-086ba2ff44dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "тип кодирования 1: OneHot, 2: LabelEncoder, 3: frequency 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово, размер:  (165034, 20) (110023, 19)\n"
     ]
    }
   ],
   "source": [
    "train, test = mc.encoder(train, test, aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71de9169-c87a-4c95-bb73-354f0d11425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(aggs, axis=1)\n",
    "test = test.drop(aggs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "827bfd6e-d9a3-4f9a-a6b2-6d4cc7afef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"data/train_n.csv\")\n",
    "test.to_csv(\"data/test_n.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bb85e9-dcb7-475c-a272-45ab3c92397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['exited'], axis = 1)\n",
    "Y = train['exited']\n",
    "\n",
    "test_cv = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4767894-071c-422a-a2de-e1ff58137a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = train.columns.astype(str)\n",
    "test.columns = test.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17745ae1-ad34-4a7d-bdee-f8c0105c152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Fold 0 ==> RF oof ROC-AUC score is ==> 0.8792879725878232\n",
      "Fold 0 ==> ET oof ROC-AUC score is ==> 0.8552482419398224\n",
      "Fold 0 ==> Hist oof ROC-AUC score is ==> 0.8874158137446392\n",
      "[LightGBM] [Info] Number of positive: 27937, number of negative: 104090\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 132027, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211601 -> initscore=-1.315304\n",
      "[LightGBM] [Info] Start training from score -1.315304\n",
      "Fold 0 ==> LGBM oof ROC-AUC score is ==> 0.890118900458089\n",
      "Fold 0 ==> XGB oof ROC-AUC score is ==> 0.8900231122094434\n",
      "Fold 0 ==> CatBoost oof ROC-AUC score is ==> 0.8894864471155329\n",
      "Fold 0 ==> Average Ensemble oof ROC-AUC score is ==> 0.8885076506688792\n",
      "Fold 0 ==> Hill Climbing Ensemble oof ROC-AUC score is ==> 0.8903386758625146\n",
      "----------------------------------------------------------\n",
      "Fold 1 ==> RF oof ROC-AUC score is ==> 0.8803560591544732\n",
      "Fold 1 ==> ET oof ROC-AUC score is ==> 0.856265653007017\n",
      "Fold 1 ==> Hist oof ROC-AUC score is ==> 0.8874782860161724\n",
      "[LightGBM] [Info] Number of positive: 27937, number of negative: 104090\n",
      "[LightGBM] [Info] Total Bins 1379\n",
      "[LightGBM] [Info] Number of data points in the train set: 132027, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211601 -> initscore=-1.315304\n",
      "[LightGBM] [Info] Start training from score -1.315304\n",
      "Fold 1 ==> LGBM oof ROC-AUC score is ==> 0.8896338737531461\n",
      "Fold 1 ==> XGB oof ROC-AUC score is ==> 0.8898201571092345\n",
      "Fold 1 ==> CatBoost oof ROC-AUC score is ==> 0.8891447919078017\n",
      "Fold 1 ==> Average Ensemble oof ROC-AUC score is ==> 0.8885826680151961\n",
      "Fold 1 ==> Hill Climbing Ensemble oof ROC-AUC score is ==> 0.8899543674005184\n",
      "----------------------------------------------------------\n",
      "Fold 2 ==> RF oof ROC-AUC score is ==> 0.8811981968193703\n",
      "Fold 2 ==> ET oof ROC-AUC score is ==> 0.8580672467949426\n",
      "Fold 2 ==> Hist oof ROC-AUC score is ==> 0.8881708154109333\n",
      "[LightGBM] [Info] Number of positive: 27937, number of negative: 104090\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 132027, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211601 -> initscore=-1.315304\n",
      "[LightGBM] [Info] Start training from score -1.315304\n",
      "Fold 2 ==> LGBM oof ROC-AUC score is ==> 0.8909923457876874\n",
      "Fold 2 ==> XGB oof ROC-AUC score is ==> 0.8912225864255512\n",
      "Fold 2 ==> CatBoost oof ROC-AUC score is ==> 0.8904399278213619\n",
      "Fold 2 ==> Average Ensemble oof ROC-AUC score is ==> 0.8898397175218908\n",
      "Fold 2 ==> Hill Climbing Ensemble oof ROC-AUC score is ==> 0.8913577045840892\n",
      "----------------------------------------------------------\n",
      "Fold 3 ==> RF oof ROC-AUC score is ==> 0.8814287805698464\n",
      "Fold 3 ==> ET oof ROC-AUC score is ==> 0.8572504340388815\n",
      "Fold 3 ==> Hist oof ROC-AUC score is ==> 0.8889461546413538\n",
      "[LightGBM] [Info] Number of positive: 27936, number of negative: 104091\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 132027, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211593 -> initscore=-1.315349\n",
      "[LightGBM] [Info] Start training from score -1.315349\n",
      "Fold 3 ==> LGBM oof ROC-AUC score is ==> 0.891019024868941\n",
      "Fold 3 ==> XGB oof ROC-AUC score is ==> 0.8909239041003078\n",
      "Fold 3 ==> CatBoost oof ROC-AUC score is ==> 0.8905478416011297\n",
      "Fold 3 ==> Average Ensemble oof ROC-AUC score is ==> 0.8899366633607255\n",
      "Fold 3 ==> Hill Climbing Ensemble oof ROC-AUC score is ==> 0.8912133211218722\n",
      "----------------------------------------------------------\n",
      "Fold 4 ==> RF oof ROC-AUC score is ==> 0.8784161166210316\n",
      "Fold 4 ==> ET oof ROC-AUC score is ==> 0.8546584524963149\n",
      "Fold 4 ==> Hist oof ROC-AUC score is ==> 0.8856866575053288\n",
      "[LightGBM] [Info] Number of positive: 27937, number of negative: 104091\n",
      "[LightGBM] [Info] Total Bins 1378\n",
      "[LightGBM] [Info] Number of data points in the train set: 132028, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.211599 -> initscore=-1.315314\n",
      "[LightGBM] [Info] Start training from score -1.315314\n",
      "Fold 4 ==> LGBM oof ROC-AUC score is ==> 0.8874812003729684\n",
      "Fold 4 ==> XGB oof ROC-AUC score is ==> 0.8873048059915467\n",
      "Fold 4 ==> CatBoost oof ROC-AUC score is ==> 0.8869412682175791\n",
      "Fold 4 ==> Average Ensemble oof ROC-AUC score is ==> 0.8864932487736388\n",
      "Fold 4 ==> Hill Climbing Ensemble oof ROC-AUC score is ==> 0.887698689706824\n"
     ]
    }
   ],
   "source": [
    "ens_cv_scores, ens_preds = list(), list()\n",
    "hill_ens_cv_scores, hill_ens_preds =  list(), list()\n",
    "\n",
    "sk = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 1, random_state = 42)\n",
    "for i, (train_idx, test_idx) in enumerate(sk.split(X, Y)):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    Y_train, Y_test = Y.iloc[train_idx], Y.iloc[test_idx]\n",
    "    \n",
    "    print('----------------------------------------------------------')\n",
    "    \n",
    "    ########\n",
    "    ## RF ##\n",
    "    ########\n",
    "\n",
    "    RF_md = RandomForestClassifier(n_estimators = 2000, \n",
    "                                   max_depth = 6,\n",
    "                                   min_samples_split = 15,\n",
    "                                   min_samples_leaf = 10).fit(X_train, Y_train)\n",
    "    \n",
    "    RF_pred = RF_md.predict_proba(X_test)[:, 1]\n",
    "    RF_score = roc_auc_score(Y_test, RF_pred)\n",
    "\n",
    "    print('Fold', i, '==> RF oof ROC-AUC score is ==>', RF_score)\n",
    "\n",
    "    RF_pred_test = RF_md.predict_proba(test_cv)[:, 1]\n",
    "    \n",
    "    #################\n",
    "    ## Extra Trees ##\n",
    "    #################\n",
    "\n",
    "    ET_md = ExtraTreesClassifier(n_estimators = 2000, \n",
    "                                 max_depth = 6,\n",
    "                                 min_samples_split = 15,\n",
    "                                 min_samples_leaf = 10).fit(X_train, Y_train)\n",
    "\n",
    "    ET_pred = ET_md.predict_proba(X_test)[:, 1]\n",
    "    ET_score = roc_auc_score(Y_test, ET_pred)\n",
    "\n",
    "    print('Fold', i, '==> ET oof ROC-AUC score is ==>', ET_score)\n",
    "\n",
    "    ET_pred_test = ET_md.predict_proba(test_cv)[:, 1]\n",
    "\n",
    "    ##########################\n",
    "    ## HistGradientBoosting ##\n",
    "    ##########################\n",
    "\n",
    "    # hist_md = make_pipeline(StandardScaler(),\n",
    "    #                        HistGradientBoostingClassifier(l2_regularization = 0.01,\n",
    "    #                                          early_stopping = False,\n",
    "    #                                          learning_rate = 0.01,\n",
    "    #                                          max_iter = 8000,\n",
    "    #                                          max_depth = 6,\n",
    "    #                                          max_bins = 20,\n",
    "    #                                          min_samples_leaf = 15,\n",
    "    #                                          max_leaf_nodes = 10)).fit(X_train, Y_train)\n",
    "    \n",
    "    hist_md = HistGradientBoostingClassifier(l2_regularization = 0.01,\n",
    "                                             early_stopping = False,\n",
    "                                             learning_rate = 0.01,\n",
    "                                             max_iter = 500,\n",
    "                                             max_depth = 5,\n",
    "                                             max_bins = 255,\n",
    "                                             min_samples_leaf = 15,\n",
    "                                             max_leaf_nodes = 10).fit(X_train, Y_train)\n",
    "    \n",
    "    hist_pred = hist_md.predict_proba(X_test)[:, 1]\n",
    "    hist_score = roc_auc_score(Y_test, hist_pred)\n",
    "\n",
    "    print('Fold', i, '==> Hist oof ROC-AUC score is ==>', hist_score)  \n",
    "\n",
    "    hist_pred_test = hist_md.predict_proba(test_cv)[:, 1]\n",
    "\n",
    "    ##########\n",
    "    ## LGBM ##\n",
    "    ##########\n",
    "\n",
    "    LGBM_md = LGBMClassifier(objective = 'binary',\n",
    "                             n_estimators = 2000,\n",
    "                             max_depth = 6,\n",
    "                             learning_rate = 0.01,\n",
    "                             num_leaves = 20,\n",
    "                             reg_alpha = 3,\n",
    "                             reg_lambda = 3,\n",
    "                             subsample = 0.7,\n",
    "                             force_row_wise=True,\n",
    "                             colsample_bytree = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "    lgb_pred = LGBM_md.predict_proba(X_test)[:, 1]\n",
    "    lgb_score = roc_auc_score(Y_test, lgb_pred)\n",
    "\n",
    "    print('Fold', i, '==> LGBM oof ROC-AUC score is ==>', lgb_score) \n",
    "\n",
    "    lgb_pred_test = LGBM_md.predict_proba(test_cv)[:, 1]\n",
    "\n",
    "    #########\n",
    "    ## XGB ##\n",
    "    #########\n",
    "\n",
    "    XGB_md = XGBClassifier(objective = 'binary:logistic',\n",
    "                           tree_method = 'hist',\n",
    "                           colsample_bytree = 0.7, \n",
    "                           gamma = 2, \n",
    "                           learning_rate = 0.01, \n",
    "                           max_depth = 6, \n",
    "                           min_child_weight = 10, \n",
    "                           n_estimators = 2000, \n",
    "                           subsample = 0.7).fit(X_train, Y_train)\n",
    "\n",
    "    xgb_pred = XGB_md.predict_proba(X_test)[:, 1]\n",
    "    xgb_score = roc_auc_score(Y_test, xgb_pred)\n",
    "\n",
    "    print('Fold', i, '==> XGB oof ROC-AUC score is ==>', xgb_score)\n",
    "\n",
    "    xgb_pred_test = XGB_md.predict_proba(test_cv)[:, 1]\n",
    "\n",
    "    ##############\n",
    "    ## CatBoost ##\n",
    "    ##############\n",
    "\n",
    "    Cat_md = CatBoostClassifier(loss_function = 'Logloss',\n",
    "                                iterations = 2000,\n",
    "#                                 max_bin = 20,\n",
    "                                learning_rate = 0.01,\n",
    "                                depth = 6,\n",
    "                                random_strength = 0.5,\n",
    "                                bagging_temperature = 0.7,\n",
    "                                border_count = 30,\n",
    "                                l2_leaf_reg = 10,\n",
    "                                verbose = False, \n",
    "                                task_type = 'CPU').fit(X_train, Y_train)\n",
    "\n",
    "    cat_pred = Cat_md.predict_proba(X_test)[:, 1]\n",
    "    cat_score = roc_auc_score(Y_test, cat_pred)\n",
    "\n",
    "    print('Fold', i, '==> CatBoost oof ROC-AUC score is ==>', cat_score)\n",
    "\n",
    "    cat_pred_test = Cat_md.predict_proba(test_cv)[:, 1]    \n",
    "    \n",
    "    ##############\n",
    "    ## Ensemble ##\n",
    "    ##############\n",
    "    \n",
    "    ens_pred_1 = (RF_pred + ET_pred + hist_pred + lgb_pred + xgb_pred + cat_pred) / 6\n",
    "    ens_pred_2 = (RF_pred_test + ET_pred_test + hist_pred_test + lgb_pred_test + xgb_pred_test + cat_pred_test) / 6\n",
    "    \n",
    "    ens_score_fold = roc_auc_score(Y_test, ens_pred_1)\n",
    "    ens_cv_scores.append(ens_score_fold)\n",
    "    ens_preds.append(ens_pred_2)\n",
    "    \n",
    "    print('Fold', i, '==> Average Ensemble oof ROC-AUC score is ==>', ens_score_fold)\n",
    "    \n",
    "    ############################\n",
    "    ## Hill Climbing Ensemble ##\n",
    "    ############################\n",
    "    \n",
    "    x = pd.DataFrame({'RF': RF_pred,\n",
    "                      'ET': ET_pred, \n",
    "                      'Hist': hist_pred, \n",
    "                      'LGBM': lgb_pred,\n",
    "                      'XGB': xgb_pred,\n",
    "                      'Cat': cat_pred})\n",
    "    y = Y_test\n",
    "        \n",
    "    x_test = pd.DataFrame({'RF': RF_pred_test,\n",
    "                           'ET': ET_pred_test, \n",
    "                           'Hist': hist_pred_test, \n",
    "                           'LGBM': lgb_pred_test,\n",
    "                           'XGB': xgb_pred_test,\n",
    "                           'Cat': cat_pred_test})\n",
    "    \n",
    "    hill_results = mc.hill_climbing(x, y, x_test)\n",
    "    \n",
    "    hill_ens_score_fold = roc_auc_score(y, hill_results[0])\n",
    "    hill_ens_cv_scores.append(hill_ens_score_fold)\n",
    "    hill_ens_preds.append(hill_results[1])\n",
    "\n",
    "    print('Fold', i, '==> Hill Climbing Ensemble oof ROC-AUC score is ==>', hill_ens_score_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f56372a2-8383-4050-9517-556f1385c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ens_preds_test = pd.DataFrame(ens_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "# sub['smoking'] = ens_preds_test\n",
    "# sub.to_csv('ens_sub.csv', index = False)\n",
    "\n",
    "ens_preds_test = pd.DataFrame(hill_ens_preds).apply(np.mean, axis = 0)\n",
    "\n",
    "# sub['smoking'] = ens_preds_test\n",
    "# sub.to_csv('hill_sub.csv', index = False)\n",
    "\n",
    "sub[\"Exited\"] = ens_preds_test\n",
    "if os.path.exists(\"submission\") == False:\n",
    "    os.mkdir(\"submission\")\n",
    "sub.to_csv(\"submission/hill_sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27769e40-0483-4d1c-965a-b0addfbab567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
