{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40662ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72133c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed952d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_kmeans.csv',\n",
       " 'sample_submission.csv',\n",
       " 'test.csv',\n",
       " 'test_best.csv',\n",
       " 'test_dr_f.csv',\n",
       " 'test_kmeans.csv',\n",
       " 'test_max_sign.csv',\n",
       " 'test_new.csv',\n",
       " 'train.csv',\n",
       " 'train_best.csv',\n",
       " 'train_dr_f.csv',\n",
       " 'train_kmeans.csv',\n",
       " 'train_max_sign.csv',\n",
       " 'train_new.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc656366-90bf-40f9-ae0e-42f8dba68ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train_oof.csv')\n",
    "test = pd.read_csv('data/test_oof.csv')\n",
    "sub = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "test = test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34efb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"data/train_best.csv\")\n",
    "# test = pd.read_csv(\"data/test_best.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01bbd765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 10), (2500, 9))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aab685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = data.drop(\"target\",axis=1), data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36347bc-c4b4-43fe-b409-d1645e0f8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_optim(x, y, model, dict_params, scoring='roc_auc', random_state=42, cv=5):\n",
    "\n",
    "    bayes_cv_tuner = BayesSearchCV(\n",
    "        estimator = model(\n",
    "        silent=True\n",
    "        ),\n",
    "        search_spaces = dict_params,\n",
    "        cv=cv,\n",
    "        scoring = scoring,\n",
    "        n_jobs = -1,\n",
    "    #     n_iter = 100,\n",
    "        verbose = 1,\n",
    "        refit = True,\n",
    "        random_state = random_state\n",
    "        )\n",
    "    bayes_cv_tuner.fit(x, y)\n",
    "    print(bayes_cv_tuner.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23323de-dd74-477c-b4d7-045835a6b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "bayes_cv_tuner_xgb = BayesSearchCV(\n",
    "    estimator = xgb.XGBClassifier(\n",
    "    # silent=True\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        # \"booster\": (\"gbtree\", \"gblinear\"),\n",
    "        \"n_estimators\": (800, 3000),\n",
    "    \"learning_rate\": (0.0001, 0.01),\n",
    "    \"gamma\" : (0, 30),\n",
    "    \"max_depth\": (2, 20),\n",
    "    \"subsample\": (0.3, 0.9),\n",
    "    \"min_child_weight\": (1, 20),\n",
    "    \"colsample_bytree\": (0.1, 0.7),\n",
    "    \"max_delta_step\": (1, 20),\n",
    "#     \"colsample_bynode\": (0.1, 0.7),\n",
    "    \"lambda\": (1, 20),\n",
    "    \"alpha\" : (1, 20)\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,\n",
    "#     n_iter = 100,\n",
    "    verbose = 1,\n",
    "    refit = True,\n",
    "    random_state = 42\n",
    "    )\n",
    "np.int = int\n",
    "resultXGB = bayes_cv_tuner_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597763fb-c49f-434a-a084-2d9fd5abfdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('alpha', 1),\n",
       "             ('colsample_bytree', 0.7),\n",
       "             ('gamma', 5),\n",
       "             ('lambda', 1),\n",
       "             ('learning_rate', 0.003419782719339618),\n",
       "             ('max_delta_step', 3),\n",
       "             ('max_depth', 8),\n",
       "             ('min_child_weight', 2),\n",
       "             ('n_estimators', 2466),\n",
       "             ('subsample', 0.31098721316506717)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f84488-fcbe-4e04-8c0c-ce44479b7ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m dict_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m2000\u001b[39m),\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m15\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     \"iterations\": (100, 500)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[1;32m---> 11\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mbayes_optim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCatBoostClassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m, in \u001b[0;36mbayes_optim\u001b[1;34m(x, y, model, dict_params, scoring, random_state, cv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbayes_optim\u001b[39m(x, y, model, dict_params, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      3\u001b[0m     bayes_cv_tuner \u001b[38;5;241m=\u001b[39m BayesSearchCV(\n\u001b[0;32m      4\u001b[0m         estimator \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m      5\u001b[0m         silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m         random_state \u001b[38;5;241m=\u001b[39m random_state\n\u001b[0;32m     15\u001b[0m         )\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mbayes_cv_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(bayes_cv_tuner\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\searchcv.py:466\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\searchcv.py:512\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 512\u001b[0m     optim_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\searchcv.py:400\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate n_jobs parameters and evaluate them in parallel.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;66;03m# get parameter values to evaluate\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# convert parameters to python native types\u001b[39;00m\n\u001b[0;32m    403\u001b[0m params \u001b[38;5;241m=\u001b[39m [[np\u001b[38;5;241m.\u001b[39marray(v)\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p] \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:395\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    393\u001b[0m X \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points):\n\u001b[1;32m--> 395\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[0;32m    398\u001b[0m     ti_available \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mps\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macq_func \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(opt\u001b[38;5;241m.\u001b[39myi) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:367\u001b[0m, in \u001b[0;36mOptimizer.ask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Query point or multiple points at which objective should be evaluated.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mn_points : int or None, default: None\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_points \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m supported_strategies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_min\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_max\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(n_points, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m n_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:434\u001b[0m, in \u001b[0;36mOptimizer._ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_estimator_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;66;03m# this will not make a copy of `self.rng` and hence keep advancing\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;66;03m# our random state.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;66;03m# The samples are evaluated starting form initial_samples[0]\u001b[39;00m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples[\n\u001b[0;32m    438\u001b[0m             \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_initial_points]\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\space.py:900\u001b[0m, in \u001b[0;36mSpace.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    897\u001b[0m columns \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdimensions:\n\u001b[1;32m--> 900\u001b[0m     columns\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# Transpose\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _transpose_list_array(columns)\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\space.py:158\u001b[0m, in \u001b[0;36mDimension.rvs\u001b[1;34m(self, n_samples, random_state)\u001b[0m\n\u001b[0;32m    156\u001b[0m rng \u001b[38;5;241m=\u001b[39m check_random_state(random_state)\n\u001b[0;32m    157\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rvs\u001b[38;5;241m.\u001b[39mrvs(size\u001b[38;5;241m=\u001b[39mn_samples, random_state\u001b[38;5;241m=\u001b[39mrng)\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\space.py:528\u001b[0m, in \u001b[0;36mInteger.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03m   original space.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;66;03m# The concatenation of all transformed dimensions makes Xt to be\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;66;03m# of type float, hence the required cast back to int.\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m inv_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mInteger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inv_transform, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    530\u001b[0m     inv_transform \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(inv_transform)\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\space.py:168\u001b[0m, in \u001b[0;36mDimension.inverse_transform\u001b[1;34m(self, Xt)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, Xt):\n\u001b[0;32m    165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Inverse transform samples from the warped space back into the\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m       original space.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\transformers.py:309\u001b[0m, in \u001b[0;36mPipeline.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minverse_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transformer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 309\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\skopt\\space\\transformers.py:275\u001b[0m, in \u001b[0;36mNormalize.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    273\u001b[0m X_orig \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_int:\n\u001b[1;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mround(X_orig)\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X_orig\n",
      "File \u001b[1;32mC:\\Program Files\\Pyhton\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "dict_params = {\n",
    "    \"n_estimators\": (500, 2000),\n",
    "    \"max_depth\": (3, 15),\n",
    "    \"subsample\" : (0.3, 0.7),\n",
    "#     \"leaf_estimation_iterations\": (5, 150),\n",
    "    \"colsample_bylevel\": (0.3, 0.9),\n",
    "    \"l2_leaf_reg\": (2, 30),\n",
    "    \"learning_rate\": (0.0001, 0.01),\n",
    "#     \"iterations\": (100, 500)\n",
    "    }\n",
    "r = bayes_optim(x_train, y_train, cb.CatBoostClassifier, dict_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f806c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_cv_tuner_cb = BayesSearchCV(\n",
    "    estimator = cb.CatBoostClassifier(\n",
    "    silent=True\n",
    "    ),\n",
    "    search_spaces = {\n",
    "    \"n_estimators\": (500, 2000),\n",
    "    \"max_depth\": (3, 15),\n",
    "    \"subsample\" : (0.3, 0.7),\n",
    "#     \"leaf_estimation_iterations\": (5, 150),\n",
    "    \"colsample_bylevel\": (0.3, 0.9),\n",
    "    \"l2_leaf_reg\": (2, 30),\n",
    "    \"learning_rate\": (0.0001, 0.01),\n",
    "#     \"iterations\": (100, 500)\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,\n",
    "#     n_iter = 100,\n",
    "    verbose = 1,\n",
    "    refit = True,\n",
    "    random_state = 72\n",
    "    )\n",
    "# resultCAT = bayes_cv_tuner_cb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2eb7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "resultCAT = bayes_cv_tuner_cb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6073e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bylevel', 0.5853177112754828),\n",
       "             ('l2_leaf_reg', 22),\n",
       "             ('learning_rate', 0.009906548674016816),\n",
       "             ('max_depth', 3),\n",
       "             ('n_estimators', 1993),\n",
       "             ('subsample', 0.5000411100811685)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_cb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e168d668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5dfd6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('alpha', 2),\n",
       "             ('colsample_bytree', 0.5528885130826658),\n",
       "             ('eta', 0.009432219749289407),\n",
       "             ('gamma', 2),\n",
       "             ('lambda', 4),\n",
       "             ('max_depth', 19),\n",
       "             ('subsample', 0.8217302497223249)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19baea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "bayes_cv_tuner_rf = BayesSearchCV(\n",
    "    estimator = RandomForestClassifier(\n",
    "#     silent=True\n",
    "    ),\n",
    "    search_spaces = {\n",
    "    \"n_estimators\": (100, 2000),\n",
    "    \"max_depth\" : (2, 20),\n",
    "    \"min_samples_split\": (2, 100),\n",
    "    \"min_samples_leaf\": (2, 20),\n",
    "#     \"min_sample_split \": (2, 50),\n",
    "#     \"max_features \": (\"sqrt\", \"log2\"),\n",
    "    },\n",
    "#     cv=5,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,\n",
    "#     n_iter = 100,\n",
    "    verbose = 1,\n",
    "    # refit = True,\n",
    "    random_state = 42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f614f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "np.int = int\n",
    "resulrf = bayes_cv_tuner_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_cv_tuner_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c84614db",
   "metadata": {},
   "outputs": [],
   "source": [
    "    lgbm_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'n_estimators': 750,\n",
    "    'learning_rate': 0.005134,\n",
    "    'num_leaves': 54,\n",
    "    'max_depth': 10,\n",
    "    'subsample_for_bin': 240000,\n",
    "    'reg_alpha': 0.436193,\n",
    "    'reg_lambda': 0.479169,\n",
    "    'colsample_bytree': 0.508716,\n",
    "    'min_split_gain': 0.024766,\n",
    "    'subsample': 0.7,\n",
    "    'is_unbalance': False,\n",
    "    'random_state': 42,\n",
    "    'silent': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "\n",
    "bayes_cv_tuner_lgbm = BayesSearchCV(\n",
    "    estimator = LGBMClassifier(\n",
    "#     silent=True\n",
    "    ),\n",
    "    search_spaces = {\n",
    "    \"learning_rate\": (0.0001, 0.1),\n",
    "    \"max_depth\" : (2, 20),\n",
    "    \"subsample\": (0.4, 0.8),\n",
    "    \"colsample_bytree\": (0.001, 0.1),\n",
    "#     \"min_sample_split \": (2, 50),\n",
    "#     \"max_features \": (\"sqrt\", \"log2\"),\n",
    "    },\n",
    "#     cv=5,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = 1,\n",
    "#     n_iter = 100,\n",
    "    verbose = 1,\n",
    "    refit = True,\n",
    "    random_state = 72\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d78b2ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "resulrf = bayes_cv_tuner_lgbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb190426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('colsample_bytree', 0.0626668954124053),\n",
       "             ('learning_rate', 0.1),\n",
       "             ('max_depth', 2),\n",
       "             ('subsample', 0.7789842765159666)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_cv_tuner_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5a6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
